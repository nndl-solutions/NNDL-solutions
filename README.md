# NNDL-solutions

> Solutions (math and code) of the exercises and problems from Michael Nielsen's book [*Neural Networks And Deep Learning*](http://neuralnetworksanddeeplearning.com/) (and adaptations to the code for Python 3 and Theano 1.0.3).

Here's where to find the solutions to exercises and problems:
* involving math:  `notebooks`
* involving code: implemented in `code`, discussed in `notebooks`

With links to nbviewer:

* [Chapter 0:Â Update the code for Python 3](https://nbviewer.jupyter.org/github/TimotheeChauvin/NNDL-solutions/blob/master/notebooks/chap-0-update-code-for-python3.ipynb)
* [Chapter 1: Using neural nets to recognize handwritten digits](https://nbviewer.jupyter.org/github/TimotheeChauvin/NNDL-solutions/blob/master/notebooks/chap-1-using-neural-nets-to-recognize-handwritten-digits.ipynb)
* [Chapter 2: How the backpropagation algorithm works](https://nbviewer.jupyter.org/github/timotheechauvin/NNDL-solutions/blob/master/notebooks/chap-2-how-the-backpropagation-algorithm-works.ipynb)
* [Chapter 3: Improving the way neural networks learn](https://nbviewer.jupyter.org/github/timotheechauvin/NNDL-solutions/blob/master/notebooks/chap-3-improving-the-way-neural-networks-learn.ipynb)
* [Chapter 4: A visual proof that neural nets can compute any function](https://nbviewer.jupyter.org/github/timotheechauvin/NNDL-solutions/blob/master/notebooks/chap-4-a-visual-proof-that-neural-nets-can-compute-any-function.ipynb)
* [Chapter 5: Why are deep neural networks hard to train?](https://nbviewer.jupyter.org/github/timotheechauvin/NNDL-solutions/blob/master/notebooks/chap-5-why-are-deep-neural-networks-hard-to-train.ipynb)
* [Chapter 6: Deep learning](https://nbviewer.jupyter.org/github/timotheechauvin/NNDL-solutions/blob/master/notebooks/chap-6-deep-learning.ipynb) (in progress)

## TODO

So far, I've provided solutions to all exercises and problems, except:

* chap3 p8, p9
* chap4 p1 (b) and (c)
* chap6 p5, p7 (theano part)